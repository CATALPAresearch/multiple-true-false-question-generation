In Abschnitt 1.3 haben wir untersucht, wie das Betriebssystem mit Hilfe des Mechanismus der Unterbrechung die Geräte steuert. Wir wollen uns in diesem Abschnitt damit beschäftigen, wie das Betriebssystem die Ausführung von Programmen ermöglicht und warum wir das Gefühl haben, dass mehrere Prozesse quasiparallel laufen.
In Abschnitt 1.3.4 haben wir beobachtet, was geschieht, wenn die CPU bei der Ausführung eines Programms unterbrochen wird: Die Adresse des nächs- ten auszuführenden Befehls und die Registerinhalte werden im Systemstapel gespeichert; damit wird die CPU für andere Aufgaben frei. Später können die Registerinhalte wieder geladen werden, und die CPU kann ihre Arbeit an der richtigen Stelle fortsetzen, so als hätte es die Unterbrechung nicht gegeben.
Ein Programm, das sich gerade in Ausführung befindet, heißt Prozess. Zum Prozess gehört aber nicht nur ein Programm (Code, der ausgeführt werden soll), sondern auch der Prozesskontext bestehend aus
• den Registerinhalten, insbesondere Befehlszähler und • Grenzen des Adressraums, sowie der
• Prozessnummer,
• Priorität (benötigt)
• Modus (im Systemmodus- oder im Benutzermodus) und
• Zustand
und anderen Informationen. Diese Angaben werden im Prozesskontrollblock (process control block = PCB) zusammengefasst. Der PCB steht im Speicher- bereich des Betriebssystems und ist somit vor dem Zugriff durch Anwendungs- programme geschützt.
Ein Prozess wird zu irgendeinem Zeitpunkt erzeugt, z. B. durch einen anderen Prozess, und zu einem späteren Zeitpunkt beendet, wenn er mit der Bearbeitung fertig ist. Dazwischen kann er mehrfach zwischen drei Zuständen wechseln, die in Abbildung 1.10 dargestellt sind. Nach der Erzeugung eines Prozesses wird der PCB vom PCB vom Betriebssystem amgelegt und initialisiert, d. h. die benötigten Ressourcen wie z. B. ein Speicherbereich werden zugeteilt. Nun ist der Prozess bereit für die Bearbeitung und er geht in den Zustand bereit.
Bei den Einprozessorsystemen, wie wir sie in diesem Kurs betrachten, ist zu jedem Zeitpunkt genau ein Prozess im Zustand rechnend; nämlich der Pro- zess, dessen Programm gerade von der CPU ausgeführt wird. Jeder andere existierende Prozess ist entweder bereit und bewirbt sich mit den übrigen be- reiten Prozessen um die Zuteilung der CPU, oder er ist blockiert und wartet darauf, dass seine Ein-/Ausgabeanforderung erledigt wird oder ein bestimmtes Ereignis eintritt.
Wenn zum Beispiel ein laufendes Benutzerprogramm auf eine Eingabe von der Tastatur wartet, führt es einen Systemaufruf durch. Bei der Durchführung des Systemaufrufs durch das Betriebssystem wird der Prozess vom Zustand rechnend in den Zustand blockiert versetzt, da er ohne die Eingabedaten nicht weiterarbeiten kann.
Danach ist die CPU frei, um andere Prozesse zu bearbeiten. Wenn dann die Daten bereitstehen und der Tastaturcontroller eine Unterbrechung auslöst, wird der Benutzerprozess in den Zustand bereit gebracht, denn seine Arbeit kann nun weitergehen. Das heißt aber nicht, dass er sofort die CPU zugeteilt
bekommt: Welcher der bereiten Prozesse als nächster rechnen darf, entscheidet der CPU-Scheduler. Der Scheduler definiert die Ausführungsreihenfolge der bereiten Prozesse im nächsten Zeitabschnitt. Er kann seine Entscheidungen nach unterschiedlichen Strategien treffen, siehe auch Abschnitt 1.4.2. Der Dispatcher führt den Prozesswechsel durch.
Ein rechnender Prozess kann auch durch einen Systemaufruf mitteilen, dass er auf ein bestimmtes Ereignis warten will; er wird dann blockiert und kommt in eine spezielle Warteschlange, in der möglicherweise noch andere blockierte Prozesse stehen, die auf dasselbe Ereignis warten. Wenn dann dieses Ereignis eintritt, kann der Prozess, welcher es auslöst, ein Signal abschicken. Dieses Signal bewirkt, dass alle Prozesse aus der Warteschlange wieder in den Zustand bereit versetzt werden.
Wenn ein Prozess im Zustand rechnend ist, muss er irgendwann die CPU wieder abgeben. Grundsätzlich gibt es zwei Arten, wie entschieden wird, wie ein Prozess vom Zustand rechnend in den Zustand bereit gehen kann: 1. Bei einem nicht präemptiven System gibt ein Prozess die CPU freiwillig ab. Man bezeichnet so ein System auch als kooperatives System.
2. Bei einem präemptiven System wird einem Prozess die CPU entzogen. Die meisten modernen Systeme sind präemptive Systeme.
Wir betrachten zwei Scheduling-Strategien für ein nicht präemptives System:
• Bei FCFS (first-come, first-served) darf zuerst rechnen, wer zuerst kommt; vergleiche Abschnitt 1.2.3. Dieses Verfahren ist leicht zu imple- mentieren; es genügt, eine Warteschlange (queue) einzurichten, bei der immer der erste Prozess als nächster an die Reihe kommt und neu eintref- fende bereite Prozesse sich hinten anstellen. Der Nachteil: Ein früh ein- treffender Prozess mit hohem Rechenzeitbedarf oder einer Endlosschleife hält alle späteren Prozesse auf.
• Das Verfahren SJF (shortest job first) kann den Nachteil von FCFS ver- meiden; hier werden die Prozesse im Zustand bereit in der Reihenfolge aufsteigenden Rechenzeitbedarfs bearbeitet: die kurzen zuerst. Voraussetzung für eine sinnvolle Anwendung von SJF ist, dass sich die benötigte
Rechenzeit (bis zur nächsten Unterbrechung) aus Erfahrungswerten gut vorhersagen lässt. Unter dieser Voraussetzung ist SJF sehr effizient, wie die folgende Aufgabe zeigt.
Das Verfahren SJF eignet sich besonders gut für den Stapel- oder Batch- Betrieb, bei dem der Rechner gleich einen ganzen Schub von Aufträgen (jobs) erhält, die keine Interaktion mit dem Benutzer erfordern und regelmäßig auszuführen sind, so dass man ihre Laufzeiten in etwa kennt.
Moderne Rechner werden meist im Time-Sharing-Betrieb verwendet: Mehrere Benutzer können zur selben Zeit an einem Rechner arbeiten, und jeder kann gleichzeitig mehrere Programme laufen lassen, zum Beispiel in einem Fenster einen Compiler, in einem anderen ein Werkzeug für elektronische Post und in einem dritten Fenster einen WWW-Browser.
Diese "Gleichzeitigkeit" ist natürlich eine Illusion, denn bei einem Computer mit nur einer CPU kann nur ein einziger Prozess rechnend sein. Der Eindruck von Gleichzeitigkeit entsteht dadurch, dass der Scheduler in schnellem Wechsel jedem bereiten Prozess ein gewisses Quantum an Rechenzeit zukommen lässt. Wenn das Quantum verbraucht wird, wird dem Prozess die CPU entzogen. Danach erfolgt die Umschaltung zwischen den Prozessen, die so schnell ist, dass die Unterbrechungen nicht spürbar werden.
Drei Strategien können wir uns für präemptive Systeme vorstellen:
1. Ein sehr einfaches Verfahren namens Round Robin ist weit verbreitet, bei dem jeder Prozess im Zustand bereit vom Scheduler eine Zeitscheibe (time slice) derselben Länge an Rechenzeit zugewiesen bekommt und die Prozesse im Zustand bereit reihum bedient werden. Dazu kann man sie in der Reihenfolge ihres Eintreffens in einer kreisförmigen Warteschlange speichern. Bei der Strategie Round Robin werden alle Prozesse gleich behandelt. Diese Eigenschaft kann auch ein Nachteil für die interaktiven Prozesse sein, die oft eine Eingabe oder Ausgabe benötigen, wenn z.B. die Länge der Zeitscheibe zu groß gewählt wird.
2. Eine Verbesserung von Round Robin ist, dass der Scheduler einem Prozess die Länge der Zeitscheibe in Abhängigkeit von der Priorität des Prozesses oder davon, wieviel Rechenzeit der Prozess insgesamt schon verbraucht hat, zuweist. Der Scheduler wählt dann den Prozess als nächsten aus, der die höchste Priorität hat. Dieses Vorgehen kann aber dazu führen, dass bei ständig neu erzeugten Prozessen mit höherer Priorität die niedrig priorisierten Prozesse, trotz längerer Zeitscheibe, nie rechnend werden.
Die Priorität eines Prozesses kann sogar nach seinem Verhalten dynamisch vergeben werden. Beispielsweise warten die interaktiven Prozesse oft auf eine Ein-/Ausgabe und sie benötigen für deren Verarbeitung nur eine kurze Zeitscheibe. Insbesondere benötigen sie hierfür aber oft die CPU, um auf die Ein-/Ausgabe reagieren zu können. Um diesem Ver- halten zu entsprechen, können sie vom Scheduler anhand dieser Charakteristik erkannt und eine kurze Zeitscheibe sowie eine höhere Priorität bekommen.
Die technische Realisierung mit der Zeitscheibe kann folgendermaßen geschiehen: Eine Hardware (Zeitgeber (Timer)) wacht darüber, dass der Prozess sein Quantum nicht überschreitet; oft ist dafür ein eigener Chip im Rechner vorhanden, der an den Takt der CPU angeschlossen ist. Die Länge der zugewie- senen Zeitscheibe wird in einem Register des Zeitgebers gespeichert. Nach jeder verstrichenen Zeiteinheit wird der Inhalt dieses Registers um Eins verringert. Ist der Wert bei Null angekommen, so ist die zugewiesene Zeitscheibe abge- laufen, und der Zeitgeber löst eine Unterbrechung der CPU aus. Der Prozess wird unterbrochen und wieder in die Menge der bereiten Prozesse eingereiht; vergleiche Abbildung 1.10. Nun kommt ein anderer Prozess an die Reihe.
Wie effizient dieses Verfahren arbeitet, hängt von der Länge der Zeitschei- ben ab. Die nächste Aufgabe zeigt, dass extreme Werte unzweckmäßig sind.
Das Umschalten zwischen Prozessen bezeichnet man auch als Kontextwechsel (context switch). Während der Scheduler die Strategie für die Rechenzeitvergabe festlegt, führt der Dispatcher die eigentlichen Kontextwechsel durch. Da solche Kontextwechsel häufig vorkommen, ist es wichtig, dass der Dispat- cher möglichst schnell arbeitet.