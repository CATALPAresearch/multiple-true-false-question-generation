Die Aufgabe der Transportschicht ist die Bereitstellung von Kommunikations- diensten für die Anwendungsprozesse, die auf den verschiedenen Endgerä- ten eines Computernetzwerks laufen. Hierbei geht es um die Unterstützung logischer Kommunikation zwischen Anwendungsprozessen auf verschiedenen Hosts, die in der Regel nicht direkt, sondern über eine Menge von dazwischen- liegenden Routern und Kommunikationsverbindungen miteinander verbunden sind. Abbildung 3.11 illustriert die Nutzung der Transportschicht durch zwei Anwendungen auf verschiedenen Hosts, die über das Rechnernetz verbunden sind. Transportprotokolle werden auf den Endgeräten (Hosts) implementiert, nicht in Routern! Router dienen lediglich zum Transport von Paketen zwischen Hosts. Sie implementieren die Dienste der Schichten 3 bis 1 (Vermittlungs- schicht bis Bitübertragungsschicht).
Transportprotokolle nutzen jedoch die Dienste der Vermittlungsschicht zur Realisierung logischer Kommunikation zwischen Prozessen (vgl. hierzu auch das Beispiel der Briefkommunikation mittels der Posttransportschicht in Ab- schnitt 3.2.1). In der Regel laufen auf einem Host mehrere Anwendungspro- zesse, die über das Rechnernetz kommunizieren wollen. Da auf Schicht 3 nur die Kommunikation zwischen Hosts unterstützt wird, muss ein Transportpro- tokoll Nachrichten verschiedener Prozesse über denselben Host senden und empfangen. Hierzu muss das Transportprotokoll den Nachrichtenstrom, den es von der Vermittlungsschicht erhält, auf die verschiedenen Empfängerprozesse verteilen. Dies nennt man Demultiplexen. Damit dies funktioniert, muss das sendende Transportprotokoll geeignete Kontrollinformationen zu den Nach- richten, die es vom Anwendungsprozess erhält, hinzufügen, bevor es sie an die Vermittlungsschicht zum Versenden übergibt. Dies nennt man Multiplexen.
Das Multiplexen/Demultiplexen muss jedes Transportprotokoll leisten, da Transportprotokolle gerade die Host-zu-Host-Übertragung der Vermittlungs- schicht um die Prozess-zu-Prozess-Kommunikation erweitern. Die Anwendun- gen stellen aber noch andere Anforderungen an die Transportschicht, wie wir in Abschnitt 3.3.3 gesehen haben. Das Internet bietet zwei unterschiedliche Transportprotokolle, die sich hinsichtlich der ersten Anforderung, der Zuver- lässigkeit des Dienstes, unterscheiden:
• Das UDP-Protokoll erlaubt das Senden einzelner Nachrichten zwischen
Prozessen. Es macht dabei keine Garantien bezüglich der Ankunft (Da-
tenverlust) und der Reihenfolge der Nachrichten. UDP funktioniert prak-
tisch wie die gelbe Post: Der Sender baut keine Verbindung zum Empfänger auf, sondern schickt die Nachrichten einfach los. Der Empfänger weiß also gar nicht, dass Nachrichten an ihn gesendet werden. UDP wird deshalb als verbindungsloser Dienst bezeichnet.
• Das TCP-Protokoll garantiert, dass die von einem Senderprozess zu einem Empfängerprozess übertragenen Nachrichten irgendwann in der richtigen Reihenfolge und vollständig beim Empfängerprozess ankom- men. Der Sender baut vor dem Übertragen der Daten eine virtuelle Verbindung zum Empfänger auf, ähnlich dem Telefonieren: Erst wenn der Empfänger den Hörer abnimmt, kann der Sender dem Empfänger die Nachricht mitteilen. TCP wird deshalb als verbindungsorientierter Dienst bezeichnet.
Für die anderen beiden Anforderungen von Anwendungen, Bandbreite und Zeit, gibt es im derzeitigen Internet keine Unterstützung. Die neue Version des Internets (IP Version 6) stellt hierfür neue Konzepte zur Verfügung, die in der einschlägigen Literatur behandelt werden.
Jedes Transportprotokoll nutzt die darunter liegende Schicht zum Senden und Empfangen von Nachrichten. Solche Schicht-4-Nachrichten werden im folgen- den als Segmente bezeichnet; siehe Abbildung 3.5 auf Seite 115. Im Internet unterstützt die Vermittlungsschicht den Nachrichtenaustausch zwischen Hosts. Jeder Host wird eindeutig durch seine IP-Adresse identifiziert. Ankommende Nachrichten (Segmente), die bei einem Host von der Vermittlungsschicht an die Transportschicht abgeliefert werden, müssen nun an die richtigen Anwen- dungsprozesse weitergeleitet werden. Wie wir in Abschnitt 3.3.4 kennen gelernt haben, werden Prozesse durch Portnummern identifiziert. Unter Verwendung von IP-Adressen und Portnummern funktioniert das Multiplexen und Demultiplexen wie folgt, siehe Abbildung 3.12.
Das sendende Transportprotokoll fügt die zu sendenden Anwendungs- daten M mit einem Segmentheader H4 zu einem Segment zusammen. Im Segmentheader gibt es insbesondere zwei Felder, die für die Identifizierung des Sender- und Empfängerprozesses verwendet werden: SourcePort und DestinationPort. Das Hinzufügen der Portnummern des Quellprozesses und des Zielprozesses gehört zum Multiplexen (Multiplexing). Das Segment wird dann an die Vermittlungsschicht zur Versendung weitergegeben.
Das empfangende Transportprotokoll erhält ein Segment von der Ver- mittlungsschicht. Mittels der Felder SourcePort und DestinationPort im Segmentheader identifiziert das Transportprotokoll den korrekten Empfänger- prozess und stellt das Segment zu. Diesen Schritt nennt man Demultiplexen (Demultiplexing). Zum Demultiplexen reicht insbesondere die Angabe der Port- nummer des Zielprozesses alleine nicht aus. Da mehrere Anwendungsprozesse desselben Typs (die ja dieselbe Portnummer nutzen) auf einem Host laufen können, wird auch die Angabe der Portnummer des Senderprozesses benötigt, um die logische Kommunikationsverbindung eindeutig zu definieren, siehe Abbildung 3.13.
Als Beispiel zu Multiplexen- und Demultiplexen betrachten wir einen Web- Server und mehrere Web-Clients, die HTTP-Anfragen zum Server senden.
Bevor ein Client eine HTTP-Anfrage sendet, muss er eine Verbindung mit dem Server aufbauen, wobei dort ein neuer Prozess mit Portnummer 80 erzeugt wird. Nun kann der Client eine Anfrage verpackt in Segmente zum Server senden. Die Portnummern von Quelle und Ziel im Header eines Segments ermöglichen das Demultiplexen.
Wenn aber Web-Clients auf verschiedenen Hosts denselben SourcePort ge- wählt haben, dann ermöglicht die eindeutige IP-Adresse im IP-Header des Datagramms die eindeutige Zuordnung des Segments zum korrekten Server- prozess. Dies wird in Abbildung 3.14 illustriert: Web-Server B kann die An- fragen mit SourcePort 12345 der Web-Clients A und C durch die Angabe der sourceIP von A und C unterscheiden.
UDP (User Datagram Protocol) ist ein einfaches Transportprotokoll, das in RFC 768 definiert ist. UDP ist ein verbindungsloser Dienst, d. h. ein Sender- prozess kann direkt UDP-Segmente verschicken, ohne vorher eine Verbindung mit dem Empfängerprozess aufgebaut zu haben. Dies entspricht der Briefzu- stellung per Post, bei der ein Absender ja auch einen Brief verschicken kann, ohne dass der Empfänger etwas davon weiß. UDP realisiert einen unzuverläs- sigen Transportdienst, d. h.
1. Nachrichten können verloren gehen.
2. Nachrichten, die in einer Reihenfolge vom Senderprozess an den Empfängerprozess gesendet werden, können in einer anderen Reihenfolge beim Empfängerprozess abgeliefert werden.
UDP macht keine Aussage über die Übertragungsverzögerung bei der Nach- richtenübertragung. UDP wird bevorzugt für einmalige Abfragen und Anwen- dungen in Client/Server-Umgebungen benutzt, in denen die Schnelligkeit der Zustellung wichtiger ist als die Genauigkeit, z.B. die Übertragung von Spra- che oder Video. Ein Beispiel für die Anwendung von UDP ist das Senden von DNS-Anfragen. Nach der DNS-Spezifikation kann DNS auch über TCP lau- fen, aber es wird fast immer über UDP realisiert, da eine DNS-Anfrage relativ klein ist und in ein UDP-Segment passt. So kann ein DNS-Server jede her- einkommende Anfrage gleich beantworten und sofort wieder vergessen. Wenn eine DNS-Anfrage erfolglos ist, kann der DNS-Client die Anfrage bei einem anderen Name-Server versuchen oder die anfragende Anwendung informieren, dass der Server nicht erreichbar ist.
Abbildung 3.15 zeigt eine typische Client-Server-Anwendung, die UDP zur Kommunikation verwendet. Ein Anwendungsprozess erzeugt zuerst einen Dienstzugangspunkt zum UDP-Dienst. Dies ist üblicherweise ein Socket vom Typ Datagramm-Socket, der dem Anwendungsprozess eine eindeutige IP- Adresse und Portnummer zuordnet. Ein Beispiel für die Verwendung von Sockets für den TCP-Dienst haben wir in Abschnitt 3.3.6 kennen gelernt. Der Anwendungsprozess kann nun von dem Socket Nachrichten empfangen oder verschicken. Bei Ende des Anwendungsprozesses wird der Socket wieder freigegeben. 
UDP-Segmente bestehen aus einem Header mit vier Feldern und einem Datenfeld mit den Anwendungsdaten. Im Header, siehe Abbildung 3.16, stehen die SourcePortnummer (2 Byte) und die DestinationPortnummer (2 Byte) zur Identifikation von Sender- und Empfängerprozess. Hinzu kommen die Länge des Segmentes (inklusive Header) in Byte (2 Byte) und eine Prüfsumme (check sum), die zur Fehlererkennung bei fehlerhafter Übertragung des Headers bzw. des Datenfeldes dient.
UDP führt eine simple Fehlererkennung ein, da nicht alle Vermittlungspro- tokolle eine Fehlererkennung oder -korrektur aufweisen. Falls UDP einen Fehler erkennt, dann wird das Segment entweder verworfen oder mit einer Warnung an den Anwendungsprozess weitergereicht. Zur Fehlererkennung speichert UDP eine Prüfsumme (2 Byte) im Header des UDP-Segments. Die UDP-Prüfsumme wird berechnet als 1er-Komplement der 1er-Komplement-Summe  aller 16- Bit-Wörter des Segments. Das UDP-Protokoll auf dem Empfänger-Host wird dann die gleiche Operation auf dem Segment durchführen, aber inklusive der Prüfsumme; hier sollte dann das Resultat 1111111111111111 herauskommen. Ist dagegen mindestens ein Bit gleich 0, dann ist ein Übertragungsfehler aufgetreten.
Eines der grundsätzlichen Probleme bei Rechnernetzen ist das Problem der zuverlässigen Datenübertragung. Grundsätzlich möchten Prozesse einen zuver- lässigen Datenübertragungsdienst, schließlich nimmt man Verluste bei Nach- richten nur ungern auf sich. Dieser Dienst soll also einen zuverlässigen Über- tragungskanal für Nachrichten realisieren. Er soll garantieren, dass
• die Daten unverändert (z. B. ohne Bitfehler),
• vollständig und
• in der Reihenfolge beim Empfängerprozess abgeliefert werden, in der sie vom Senderprozess verschickt wurden.
Das Bedürfnis nach einem zuverlässigen Datenübertragungsdienst kann prinzipiell auf jeder Schicht in einem Netzwerk auftreten. Ein solcher zuver- lässiger Übertragungskanal für Nachrichten wird dann durch ein zuverlässiges Datenübertragungsprotokoll implementiert, das einen darunter liegenden unzu- verlässigen Übertragungskanal verwendet. Das Problem bei der Implementie- rung eines solchen Protokolls liegt in der potentiellen Unzuverlässigkeit der darunter liegenden Schicht. Im Beispiel des Internet realisiert z. B. das TCP- Protokoll einen zuverlässigen Übertragungskanal in der Transportschicht. Dazu baut TCP auf dem IP-Protokoll der Vermittlungsschicht auf, das selbst wieder- um ein unzuverlässiges Host-zu-Host-Protokoll ist. Im Allgemeinen kann die Schicht unterhalb der beiden zuverlässig kommunizierenden Endpunkte aus ei- ner einzigen physikalischen Verbindung bestehen, oder ein komplexes globales Rechnernetz sein.
Man kann sich einen Dienst generell auch als abstrakten Datentyp (sie- he Kurse Datenstrukturen I, Datenstrukturen II, Datenstrukturen) vorstellen. Der Dienst definiert dann eine Datenstruktur und die darauf arbeitenden Ope- rationen. Ein Protokoll ist dann die Implementierung des Dienstes bzw. des abstrakten Datentyps, der den Dienst spezifiziert.
Ein zuverlässiger Datenübertragungsdienst kann auf einem unzuverlässi- gem Medium im Prinzip wie in Abbildung 3.17 implementiert werden.
Zuerst ruft ein Senderprozess mittels der Funktion rdt_send(daten) die Senderseite des zuverlässigen Datentransferprotokolls auf, um Daten an den Empfängerprozess zu senden (rdt steht für „reliable data transfer“). Das zu- verlässige Datentransferprotokoll verschickt die Daten mittels der darunter lie- genden unzuverlässigen Netzwerkschicht an das auf der Empfängerseite laufen- de zuverlässige Datentransferprotokoll. Dazu verwendet es die von der unter- liegenden unzuverlässigen Schicht bereitgestellte Funktion udt_send(paket) (udt steht für „unreliable data transfer“). Auf der Empfängerseite empfängt das Datentransferprotokoll die Pakete mittels der Funktion rdt_receive(paket).
Bei Fehlern in der Datenübertragung ist weitere bilaterale Kommunika- tion von Daten und Kontrollinformation zwischen der Senderseite und der Empfängerseite des zuverlässigen Datenübertragungsprotokolls notwendig, um die Fehler zu beheben. Wenn die Nachricht komplett übertragen wurde, kann der Empfänger des zuverlässigen Datentransferprotokoll mittels der Funktion deliver_data(daten) die Nachricht an den Empfängerprozess liefern. Aus der Sicht von Senderprozess und Empfängerprozess handelt es sich um einen zuverlässigen Übertragungskanal, der aber in Wirklichkeit vom zuverlässigen Datenübertragungsprotokoll mit Hilfe des unterlagerten unzuverlässigen Übertragungskanals realisiert wurde.
Kommunikationsprotokolle werden in der Regel als Zustandsautomaten be- schrieben. Hierbei beschreiben Knoten die Zustände und Pfeile die Übergänge zwischen Zuständen. An jedem Pfeil steht das Ereignis, das den Übergang auslöst, und die Operationen, die beim Übergang ausgeführt werden. Ereig- nis und Operationen sind durch einen waagerechten Strich getrennt. Den ein- fachsten Fall eines Datenübertragungsprotokolls für einen zuverlässigen Über- tragungskanal zeigt Abbildung 3.18:22 Hier gehen wir davon aus, dass der genutzte Übertragungskanal auch zuverlässig ist, d.h. rdt_receive() und udt_send() verlieren und verfälschen keine Daten.
Bei der Übertragung von Daten über einen unzuverlässigen Über- tragungskanal muss ein Transportprotokoll generell mit den folgenden Pro- blemen umgehen:
• Einzelne Bits in einer Nachricht können fehlerhaft übertragen werden. • Ganze Nachrichten können verloren gehen. • Falls die Datenrate, in der ein Empfänger Daten empfangen kann, nied- riger sein kann, als die Rate, in der ein Sender Daten senden kann, dann muss zusätzlich das Problem der Überflutung des Empfängers mit Nach- richten gelöst werden.
Im folgenden werden wir Lösungen für die ersten beiden Probleme kennen lernen. Um Überflutungen zu vermeiden, sind Techniken der Flusskontrolle notwendig.
Zur Vereinfachung der Darstellung betrachten wir im folgenden nur die unidirektionale Kommunikation von einem Senderprozess zu einem Empfän- gerprozess. Bidirektionale Kommunikation zwischen zwei Prozessen kann dann als Kombination von Sender- und Empfängerseite in einem Protokoll-Client implementiert werden.
Betrachten wir zuerst den hypothetischen Fall, dass Datenpakete über einen verlustfreien Kanal mit Bitfehlern, d. h. ohne Verlust und in der richtigen Rei- henfolge, aber ggf. mit veränderten Bits übertragen werden. Es stellt sich also das Problem, wie Bitfehler vom Protokoll zu behandeln sind. Wenn zwei Per- sonen über einen solchen Kanal, z. B. eine schlechte Telefonverbindung, einen längeren Text diktieren, dann würden sie wahrscheinlich das folgende Protokoll verwenden: der Zuhörer bestätigt nach jedem Satz, den er gehört, verstanden und aufgezeichnet hat, den Empfang, indem er „OK“ sagt. Falls der Empfän- ger einen Satz nicht versteht, z.B. wegen einer Störung, dann wird er den Sprecher um Wiederholung bitten. In diesem Protokoll werden sowohl posi- tive Bestätigungen (Acknowledgements-ACK) als auch negative Bestätigunen (Negative Acknowledgements-NACK) verwendet. In der Literatur heißen zuverlässige Datenübertragungsprotokolle, die auf Wiederholungen basieren, auch ARQ-Protokolle (Automatic Repeat reQuest).
Grundsätzlich werden in einem ARQ-Protokoll drei Fähigkeiten benötigt, um Bitfehler zu behandeln:
1. Fehlererkennung: Um Bitfehler zu erkennen, müssen zusätzliche Informa- tionen in einem Paket übertragen werden (z. B. die Prüfsumme).
2. Rückmeldung vom Empfänger: Da Senderprozess und Empfängerprozess in der Regel auf verschiedenen Hosts laufen, kann der Sender nur mittels expliziter Nachrichten etwas über den Zustand des Empfängers erfahren. In obigem Beispiel müssen die positiven (ACK) und negativen (NACK) Bestätigungen vom Empfänger zum Sender kommuniziert werden.
3. Wiederholung: Ein fehlerhaft empfangenes Paket muss vom Sender noch einmal übertragen werden.
Die Senderseite eines Protokolls für einen verlustfreien Kanal mit Bitfehlern
hat zwei Zustände, siehe Abbildung 3.19. In einem Zustand wartet das Protokoll auf Daten, die übertragen werden sollen, in dem anderen Zustand wartet das Protokoll auf eine Empfangsbestätigung des Empfängers. Falls ein NACK empfangen wird, dann sendet das Protokoll das letzte Paket noch einmal und bleibt im Wartezustand auf die Bestätigung für dieses Paket. Falls ein ACK empfangen wird, dann wurde das letzte Paket korrekt empfangen und das Protokoll kehrt in den Zustand des Wartens auf neue Daten des Senderprozesses zurück.
In dem oben beschriebenen Protokoll wartet der Sender mit der Übertragung des nächsten Pakets solange bis eine Bestätigung für das aktuel- le Paket eingetroffen ist. Deshalb heißt dieses Protokoll auch Stop-and-Wait-Protokoll.
Die Empfängerseite des Stop-and-Wait-Protokolls hat nur einen Zustand, in dem das Protokoll auf die Ankunft eines neuen Pakets wartet, siehe Ab- bildung 3.20. Das Protokoll prüft dann, z. B. anhand der Prüfsumme, ob das Datenpaket einen Bitfehler aufweist. Liegt ein Bitfehler vor, dann wird ein NACK verschickt, ansonsten werden die Anwendungsdaten extrahiert, an den Empfängerprozess weitergereicht, und ein ACK an den Sender zurückgeschickt.
Unglücklicherweise ist das oben skizzierte Protokoll nicht in der Lage, mit Bitfehlern in den Bestätigungen umzugehen. Dieses Problem kann prinzipiell auf zwei Arten gelöst werden:
1. Durch Hinzufügen einer genügend langen Prüfsumme kann der Sender nicht nur einen Bitfehler in einer Bestätigungsnachricht erkennen, son- dern diesen auch beheben. Dies löst das Problem eines fehlerhaften Ka- nals, der keine Pakete verliert.
2.
Bei Empfang eines verfälschten ACK oder NACK kann der Sender nicht entscheiden, ob der Empfänger ein ACK oder NACK senden wollte. In diesem Fall kann der Sender einfach das aktuelle Datenpaket erneut sen- den. Dies führt aber zu duplizierten Paketen im Nachrichtenstrom vom Sender zum Empfänger. Der Empfänger hat nun das Problem, dass er nicht weiß, ob das letzte gesendete ACK/NACK korrekt vom Sender empfangen wurde (und ob daher das aktuelle Paket eine Wiederholung ist oder nicht). Üblicherweise wird dieses Problem durch Hinzufügen eines neuen Feldes Sequenznummer im Paketheader gelöst. Der Sender num- meriert nun alle gesendeten Pakete und trägt in dieses neue Feld die Sequenznummer des Pakets ein. Damit kann der Empfänger einfach prüfen, ob ein empfangenes Paket eine Wiederholung mit alter Sequenznummer oder ein neues Paket ist. Für den einfachen Fall unseres Stop-and-Wait-Protokolls genügt ein einzelnes Bit zur Nummerierung, um die Pakete zu unterscheiden. Da wir annehmen, dass der Kanal keine Pakete verliert, müssen ACK/NACK-Pakete nicht explizit die Sequenznummer des Pakets enthalten, auf das sie sich beziehen. Der Sender kann annehmen, dass sich jedes ACK/NACK, ob verfälscht oder nicht, immer auf das letzte übertragene Paket bezieht.
Abbildung 3.21 zeigt das Zustandsübergangsdiagramm der Senderseite eines Stop-and-Wait-Protokolls mit Sequenznummern. Das Protokoll kommt ohne negative Bestätigungen (NACK) aus. Wenn der Empfänger ein Paket nicht korrekt empfangen hat, sendet der Empfänger einfach ein ACK für das letzte korrekt empfangene Paket. Wenn der Sender nun zwei ACKs für dasselbe Paket P erhält, weiß er, dass der Empfänger das nachfolgende Paket von P nicht korrekt empfangen hat. Unser verbessertes Protokoll hat nun doppelt so viele Zustände wie das einfache Protokoll in Abbildung 3.19 und 3.20. Der Grund hierfür ist, dass der Zustand nun speichern muss, ob das nächste zu sendende Paket die Sequenznummer 0 oder 1 haben soll.
Nehmen wir nun an, dass der Kanal Pakete in der richtigen Reihenfolge über- trägt, aber sowohl Bitfehler verursachen als auch Pakete verlieren kann. Dies tritt bei den heute verwendeten Netzwerktechnologien durchaus häufiger auf. Ein zuverlässiges Datenübertragungsprotokoll muss nun zwei neue Aufgaben lösen:
1. Erkennung von Paketverlusten, 2. Behandlung von Paketverlusten.
Mit Hilfe der uns schon bekannten Techniken, wie z.B. Prüfsummen, Se- quenznummern, Bestätigungsnachrichten (ACK) und Wiederholungen, können wir Paketverluste behandeln. Aber wie kann ein Paketverlust bemerkt werden?
In diesem Abschnitt werden wir eine Lösung vorstellen, bei welcher der Sender die Aufgabe der Erkennung und Behandlung von Paketverlusten löst.
Nehmen wir an, der Sender überträgt ein Paket und entweder dieses Pa- ket oder das dazugehörige ACK geht verloren. In beiden Fällen kommt keine Antwort des Empfängers beim Sender an. Falls der Sender nun bereit ist, lang genug zu warten, so dass er sicher sein kann, dass ein Paket verloren wurde, dann kann der Sender nach Ablauf der Wartezeit einfach das Paket erneut übertragen. Dieses Protokoll löst unser Problem.
Die Frage ist nun: Wie lange muss der Sender warten, um sicher zu sein, dass ein Paket verloren gegangen ist? Im Prinzip müsste der Sender mindes- tens die Zeit abwarten, die ein Paket vom Sender zum Empfänger und zurück benötigt. Diese Zeit beinhaltet auch Zeiten, in denen Pakete im Internet in Routern oder Gateways24 gepuffert werden, und die Zeit der Verarbeitung des Pakets bei der Empfängerseite des Protokolls. Diese worst-case Verzögerung lässt sich in der Praxis kaum schätzen. Hinzu kommt, dass unser Protokoll möglichst rasch einen Paketverlust behandeln sollte, anstatt sehr lange darauf zu warten, dass ein Paketverlust tatsächlich sehr sicher aufgetreten ist. Des- halb wird in der Praxis eine Zeitschranke gewählt, deren Überschreitung einen Paketverlust anzeigt, obwohl eventuell gar keiner aufgetreten ist. Sobald der Sender innerhalb der Zeitschranke kein ACK für das Paket erhält, wird er das Paket wiederholen, auch wenn tatsächlich gar kein Paket oder ACK verlorenge- gangen sein mag, z. B. wegen einer Überlastung des Internets. Dies wird in den Fällen, in denen das Paket gar nicht verloren gegangen ist, zu Duplikaten füh- ren. Solche Duplikate kann der Empfänger aber anhand der Sequenznummern erkennen, bestätigen und verwerfen.
Damit der Sender das Überschreiten der Zeitschranke erkennen kann be- nötigt er einen Zeitgeber (Countdown–Timer). Der Sender muss in der Lage sein
• den Zeitgeber bei jedem gesendeten Paket zu setzen,
• bei Ablauf des Zeitgebers das verlorengegangene Paket zu wiederholen, und
• bei Ankunft einer Bestätigungsnachricht (ACK) den Zeitgeber zu stop- pen.
Die Zeit vom Starten des Countdown–Timers bis zum Ablauf nennt man auch Timeout-Intervall. Die Existenz von Duplikaten der Datenpakete oder der Bestätigungsnachrichten kompliziert für den Sender die Behandlung von Bestätigungsnachrichten. Um festzustellen, zu welchem Paket eine Bestäti- gungsnachricht gehört, muss die Sequenznummer des bestätigten Pakets vom Empfänger in ein neues Feld (Bestätigungsfeld) des ACK-Pakets geschrieben werden. Anhand dieser Sequenznummer kann der Sender feststellen, welches Paket vom Empfänger bestätigt wurde.
Abbildung 3.23 zeigt die Senderseite des oben beschriebenen Protokolls. Der aufmerksame Leser wird feststellen, dass in Abbildung 3.23 keine Zeitgeber angehalten werden, z.B. wenn ein Acknowledgement empfangen wird. Dies ist in einem Zustandsübergangsdiagramm auch nicht notwendig, da ja das Protokoll in einen neuen Zustand übergeht, in dem das Ablaufen des Zeitgebers einfach ignoriert wird. Deshalb muss der Zeitgeber in dieser Darstellung auch nicht explizit angehalten werden.
Das in Abbildung 3.23 gezeigte Protokoll erfüllt nun alle Anforderungen an ein Protokoll für die zuverlässige Datenübertragung über einen verlustbe- hafteten Kanal mit Bitfehlern. In der Literatur wird dieses Protokoll auch als Alternating-Bit-Protokoll bezeichnet, da die Sequenznummern der Pakete immer zwischen 0 und 1 alternieren.
Abbildung 3.24 zeigt in einem sogenannten Zeitdiagramm einige typische Situationen bei Ablauf des Protokolls. Häufig werden diese Situationen in sol- chen Zeitdiagrammen dargestellt. Die Zeit verläuft in solchen Diagrammen von oben nach unten. Die Spalten entsprechen hierbei den Aktionen der Akteure (Senderseite, Empfängerseite). Zwischen den beiden Akteuren stellen Pfeile den Nachrichtenfluss dar, und die Pfeilbeschriftungen identifizieren die ge- sendeten Nachrichten. Die eckigen Klammern von send paket1 zu timeout deuten an, wann der Zeitgeber abgelaufen ist.
Leider ist die Leistung des Alternating-Bit-Protokolls in der Praxis kaum ausreichend, da es ein Stop-and-Wait-Protokoll ist. Nach jeder Übertragung eines Pakets wartet das Protokoll auf die Bestätigung. In der Praxis werden deshalb Protokolle eingesetzt, die mehr als ein Paket senden dürfen, bevor eine Bestätigung des Empfängers eintreffen muss. Hierzu ist es notwendig, Pakete durchzunummerieren. Die Fenstergröße legt fest, wie viele Pakete gesendet werden dürfen, ohne dass die vorhergehenden Pakete bestätigt werden müssen. Ein sogenanntes Sendefenster enthält zu jedem Zeitpunkt sämtliche Paketnummern, die der Sender aktuell beim Versenden von Paketen benutzen darf, siehe auch Abbildung 3.25. Der Empfänger bestätigt in der Regel nicht den Empfang jedes einzelnen Paketes, sondern den Empfang einer korrekt empfangenen Paketfolge (kumulative Bestätigung). Dazu sendet er die Nummer des letzten in der Folge korrekt empfangenen Pakets. So arbeitende Protokolle heißen Fenster-Protokolle. In diesem Sinne kann z.B. das Alternating-Bit-Protokoll als Fensterprotokoll mit der Fenstergröße 1 bezeichnet werden. Für Protokolle mit einer Fenstergröße größer als 1 sind aber weitere Vorkehrungen für Feh- lerbehandlungen zu treffen: Werden Nachrichten oder Quittungen fehlerhaft übertragen oder gehen sie verloren, so kommen zusätzlich zu Zeitüberwachun- gen, die jetzt individuell pro Paket erfolgen müssen, zwei aktive Eingriffsmög- lichkeiten des Empfängers zum Einsatz:
1. Er kann den Sender auffordern, das fehlerhafte Paket und alle danach bereits gesendeten n − 1 Folgepakete erneut zu senden (go-back-n, auch Sliding-Window-Protokoll genannt).
2. Er kann den Sender auffordern, nur das fehlerhafte Paket erneut zu senden (selective-reject/repeat).
In diesem Kurs werden diese Ansätze nicht weiter behandelt. Wir gehen nur insoweit darauf ein, dass das im folgenden vorgestellte Protokoll aus der Praxis, also TCP, Konzepte der Fensterprotokolle wie Sequenznummern und kumulative Bestätigungen benutzt. Zur weiteren Vertiefung sei auf die Literatur [23, 39] oder auf weiterführende Kurse (z. B. Kommunikations- und Rechnernetze) verwiesen.
Nachdem wir in den vorangegangenen Abschnitten die Grundlagen von Transportprotokollen und den verbindungslosen Transportdienst UDP im Internet kennen gelernt haben, wollen wir uns nun mit dem zweiten Transportdienst im Internet, dem verbindungsorientierten Transportprotokoll TCP (Transmission Control Protocol), beschäftigen.
TCP realisiert einen zuverlässigen Datentransfer zwischen zwei Anwendungsprozessen. TCP arbeitet immer Punkt-zu-Punkt, d.h. zwischen genau zwei Anwendungsprozessen. TCP unterstützt Vollduplex-Datenübertragung (full-duplex) zwischen genau einem Sender und einem Empfänger. Das heißt beide Anwendungsprozesse können über eine Verbindung gleichzeitig Daten an die andere Seite schicken. Anwendungsprozesse nutzen TCP, indem sie zuerst eine Verbindung zwischen Sender und Empfänger aufbauen. Nachdem die Verbindung aufgebaut ist, kann der Senderprozess beliebige Bytefolgen über die Verbindung an den Empfänger schicken. TCP garantiert, dass die identi- sche Bytefolge beim Empfänger ankommt. Insofern funktioniert TCP wie eine Datei, in die der Sender Daten schreibt und aus welcher der Empfänger Daten liest (analog zu einer Pipe in Unix). TCP vermittelt nicht, wie UDP, einzelne Nachrichten zwischen den Anwendungsprozessen, sondern einen Datenstrom. Wenn die Anwendungsprozesse den Datenstrom zur Übertragung von Nach- richten, also Blöcken von Informationen, nutzen wollen, so müssen sie Beginn und Ende von Nachrichten selbst im Datenstrom codieren, so dass der Emp- fänger Beginn und Ende einer Nachricht erkennen kann. Wir konnten dieses Vorgehen schon am Anwendungsbeispiel in Abschnitt 3.3.6 sehen, wo das Ende einer Nachricht durch ein ’\n’ (Zeilenende-Zeichen) angezeigt wird. Auch bei HTTP in Abschnitt 3.3.2 lässt sich dies erkennen. Damit der HTTP-Server die eingehende GET-Anfragenachricht bearbeiten konnte, muss er zuerst die ge- samte Nachricht vom Socket lesen. Das Ende der Nachricht erkennt der Server an der Zeichenfolge CR LF CR LF, also zweimal das Paar Carriage Return, Line Feed hintereinander. Damit ist klar, wann eine Nachricht zu Ende ist und eine neue Nachricht beginnt.
Wenn ein Anwendungsprozess die Kommunikation beenden will, dann baut er die TCP-Verbindung wieder ab. Sobald die Verbindung abgebaut ist, können keine Daten mehr über die Verbindung übertragen werden.
Aufgrund der zentralen Bedeutung der Verbindung heißt TCP auch verbindungsorientiertes Protokoll.
Bevor Daten auf einer TCP-Verbindung übertragen werden können, muss diese Verbindung zwischen Sender-Anwendungsprozess und Empfänger- Anwendungsprozess aufgebaut werden. Analog zu UDP wird auch hier ein Socket verwendet, um eine Verbindung von einem Client-Prozess zu einem Server-Prozess zu erzeugen. Dabei gibt der Client-Prozess die IP-Adresse und die Portnummer des Server-Prozesses an. Mit dieser Information kann das TCP auf dem Client-Host (im folgenden Client-TCP genannt) eine Verbin- dung zum TCP auf dem Server-Host (im folgenden Server-TCP) aufbauen. Dabei geht der Client in drei Schritten vor; siehe Abbildung 3.26, die den Verbindungsaufbau in einem Zeitdiagramm darstellt.
1. Das Client-TCP sendet ein sogenanntes SYN-Segment27 an das Server- TCP. Dieses Segment enthält keine Anwendungsdaten, aber es hat ein spezielles Header-Feld, das SYN-Bit, auf 1 gesetzt. Zusätzlich enthält das Sequenznummer-Feld des SYN-Segments eine initiale Sequenznummer (client_isn), die das Client-TCP gewählt hat.
2. Sobald das SYN-Segment beim Server-TCP ankommt, erzeugt es eine neue Verbindung und weist ihr entsprechende Puffer und Variablen zu. Dann schickt das Server-TCP ein SYNACK-Segment27 an das Client- TCP zurück. Dieses Segment enthält noch keine Anwendungsdaten, aber es enthält drei wichtige Informationen im Segment-Header: das SYN-Bit ist auf 1 gesetzt, das Acknowledgement-Feld ist auf die gerade empfange- ne Sequenznummer client_isn+1 gesetzt und das Sequenznummer- Feld ist auf eine initiale Sequenznummer des Servers (server_isn) ge- setzt, die das Server-TCP gewählt hat. Dieses SYNACK-Segment bestä- tigt dem Client-TCP, dass das Server-TCP die Verbindung mit der in- itialen Sequenznummer client_isn des Client-TCP akzeptiert hat und dass die initiale Sequenznummer des Servers server_isn ist.
3. Sobald das Client-TCP das SYNACK-Segment empfängt, erzeugt es ebenfalls eine entsprechende Verbindung und weist ihr entsprechende Puffer und Variablen zu. Dann schickt das Client-TCP eine Bestäti- gungsnachricht. In diesem Segment ist das Acknowledgement-Feld auf server_isn+1 und das SYN-Bit auf 0 gesetzt.
Sobald diese drei Nachrichten erfolgreich ausgetauscht wurden, ist die Verbindung etabliert und die Anwendungsprozesse können Daten über die Verbin- dung übertragen. Weil beim Verbindungsaufbau genau drei Nachrichten aus- getauscht werden, heißt dieses Verfahren auch Drei-Wege-Handschlag (Three-ways handshake).
Wenn der Client die Verbindung schließen will, dann sendet er ein close Kommando an das Client-TCP. Er geht dann wie folgt vor:
1. Das Client-TCP sendet ein sogenanntes FIN-Segment an das Server- TCP. Dieses Segment enthält keine Anwendungsdaten, aber es hat ein spezielles Header-Feld, das FIN-Bit, auf 1 gesetzt.
2. Wenn das Server-TCP ein FIN-Segment empfängt, dann schickt es eine Bestätigung, ein ACK-Segment, an das Client-TCP.
3. Dann schickt das Server-TCP ein eigenes FIN-Segment, mit FIN-Bit auf 1 gesetzt, an das Client-TCP.
4. Wenn das Client-TCP das FIN-Segment empfängt, dann schickt es eine Bestätigung, ein ACK-Segment, an das Server-TCP. Nach einer bestimm- ten Wartezeit wird die Verbindung gelöscht und die zugewiesenen Resourcen (Variablen, Puffer) werden freigegeben.
Abbildung 3.27 fasst die Zustandsübergänge, die Client-TCP und Server- TCP typischerweise durchlaufen, zusammen.
Nachdem das Client-TCP das letzte FIN des Server-TCP empfangen und bestätigt hat, wartet es noch eine gewisse Zeit (die implementationsabhängig zwischen 30 Sekunden und 2 Minuten liegt) und gibt dann die Verbindungsres- sourcen frei. Diese Wartezeit ist notwendig, damit das Client-TCP die letzte Bestätigung wiederholen kann, falls sie verloren geht. Die obige Diskussion des Verbindungsmanagements von TCP hat den normalen Ablauf des Verbindungsaufbaus und -abbaus geschildert. Sonderfälle, wie z. B. den gleichzeitigen Wunsch von Client-TCP und Server-TCP, die Verbindung abzubauen, wurden nicht behandelt. Interessierte Leser werden dazu auf die gängige Literatur verwiesen (z. B. Stevens).
Sobald eine TCP-Verbindung aufgebaut ist, können sich die beiden An- wendungsprozesse gegenseitig Daten schicken. In dem Programmbeispiel in Abschnitt 3.3.6 entspricht der Verbindungsaufbau der Konstruktion des Sockets in Zeile 11 des Client-Programms auf Seite 132. Sobald der Client- Anwendungsprozess Daten in den Socket schreibt (Zeile 19), werden diese vom Client-TCP behandelt, siehe Abbildung 3.28. Das Client-TCP leitet diese Da- ten direkt in den Sendepuffer der Verbindung weiter, der beim Verbindungs- aufbau dieser Verbindung zugeordnet wurde.
TCP nimmt eine Datenmenge aus dem Sendepuffer und fügt sie in ein neu- es Segment ein. Ein TCP-Segment besteht aus einem 20-Byte-Header-Feld, einem Optionsfeld und Anwendungsdaten, siehe Abbildung 3.29. Die maxi- male Anzahl von Bytes, die in einem Segment übertragen werden können, ist implementationsabhängig und sollte passend zur Datagrammgröße der Ver- mittlungsschicht (IP-Protokoll) gewählt werden. Übliche maximale Segment- größen (Maximum Segment Size, MSS) sind z.B. 1460 Byte, 536 Byte, oder 512 Byte – jedoch maximal 64 KB in IP Version 4.
Das IP-Protokoll überträgt das TCP-Segment als IP-Datagramme und lie- fert die gesendeten Daten an das Server-TCP. Das Server-TCP speichert die empfangenen Daten im Empfangspuffer der Verbindung. Aus diesem Emp- fangspuffer kann der Server-Anwendungsprozess Daten lesen (im Program- mierbeispiel entspricht dies der Zeile 18 im Server-Programm auf Seite 134). Da TCP bidirektionale Kommunikation unterstützt, hat jede Seite der Ver- bindung eigene Sende- und Empfangspuffer, die Variablen inFromClient, outToClient, outToServer, inFromServer in Abschnitt 3.3.6.
Da das IP-Protokoll ein unzuverlässiges Datenübertragungsprotokoll ist, muss TCP zusätzlich Datenverluste erkennen und beheben und die gleichbleibende Reihenfolge der übertragenen Daten garantieren, vergleiche die Situationen in Abbildung 3.17 auf Seite 143.
TCP realisiert einen Datenstrom von Bytes zwischen Sender und Empfän- ger. Jedes Byte in diesem Bytestrom wird nummeriert, diese Nummer nennen wir die Bytestromnummer. Die Sequenznummer eines Segments ist definiert als die Bytestromnummer des ersten Bytes im Segment. Betrachten wir das Beispiel eines Anwendungsprozesses, der über eine TCP-Verbindung eine Datei von 10.000 Byte an den Empfängerprozess verschicken will, wobei die maximale Segmentgröße MSS 1.000 Byte Anwendungsdaten beträgt. Der Anwendungs- prozesses schreibt dann die 10.000 Byte in den Socket, der mit der Verbindung assoziiert ist. Das Client-TCP konstruiert dann 10 Segmente und befüllt deren Datenfelder mit den Anwendungsdaten. Wenn das erste Byte mit i nummeriert wird (i = client_isn + 1, siehe Abschnitt 3.4.5.1), enthält das erste Segment die Bytes i bis i + 999, das zweite Segment die Bytes i + 1000 bis i + 1999 usw. Damit erhält das erste Segment die Sequenznummer i, das zweite Seg- ment die Sequenznummer i + 1000 usw., die im Header des entsprechenden TCP-Segments eingetragen werden.
TCP verwendet Bestätigungsnummern (Acknowledgements), um zu signa- lisieren, welches Byte als nächstes vom Sender erwartet wird. Wenn also das Server-TCP die ersten beiden Segmente korrekt empfangen hat und das dritte anfordern möchte, dann erwartet es als nächstes Byte dasjenige mit der Byte- stromnummer i + 2000. Deshalb gibt das Server-TCP die Nummer i + 2000 als Bestätigungsnummer im nächsten Segment an, welches das Server-TCP an das Client-TCP verschickt. Falls das Server-TCP Segmente empfängt, die Daten enthalten, die erst später im Datenstrom kommen (z. B. passiert dies, wenn ein vorheriges Segment verlorengegangen ist oder später ankommen wird), dann verschickt das Server-TCP als Bestätigungsnummer trotzdem nur die Num- mer des nächsten noch fehlenden Bytes im Bytestrom. TCP wendet also die kumulative Bestätigung von bis dahin korrekt empfangenen Bytes an.
Was passiert jedoch mit den Daten der Segmente, die erst nach der Lücke kommen? Implementationsabhängig kann das Server-TCP diese Daten puffern und darauf warten, dass die fehlenden Daten ankommen, und dann bis zum dann fehlenden nächsten Byte bestätigen, oder aber verwerfen und damit das Client-TCP später zur Wiederholung zwingen.
TCP benutzt zur Übertragung seiner Segmente den unzuverlässigen Über- tragungsdienst des IP-Protokolls. Insbesondere garantiert IP nicht, dass Daten- segmente unverfälscht ankommen. Deshalb fügt TCP eine eigene Prüfsumme zu jedem Segment hinzu, siehe Abbildung 3.29, und überträgt verfälschte Da- ten erneut, siehe Abschnitt 3.4.5.5. Der Algorithmus für die Bildung der Prüf- summe ist einfach: Sie ist genau das 1er-Komplement der 1er-Komplement- Summe aller 16-Bit-Wörter des Segments. Zur Kontrolle addiert der Empfän- ger alle 16-Bit-Wörter einschließlich des Headers. Wenn sich dabei die Bin- ärzahl 1111111111111111, bestehend aus 16 gesetzten Bits, ergibt, dann ist wahrscheinlich kein Fehler bei der Übertragung aufgetreten, siehe auch Ab- schnitt 3.4.3.
TCP realisiert einen zuverlässigen Datenübertragungsdienst, d. h. Daten wer- den
1. unverändert,
2. vollständig und
3. in der Reihenfolge beim Empfängerprozess abgeliefert, in der sie vom Senderprozess versendet wurden.
Um festzustellen, ob die Daten in einem TCP-Segment verändert wurden, be- rechnet der Empfänger die 1er-Komplement-Summe, siehe Abschnitt 3.4.3, auf dem empfangenen Segment inklusive der Prüfsumme im TCP-Segment- Header, siehe auch Abbildung 3.29. Die Prinzipien, die wir in Abschnitt 3.4.4 kennen gelernt haben, gelten auch hier. Zur Bestimmung eines Paketverlusts und des korrekten Empfangs wird bei der Übertragung ein einziger Timer und insbesondere die kumulative Bestätigung wie beim Sliding-Window-Protokoll verwendet, siehe Seite 153. Für die richtige Reihenfolge besitzt jedes Segment eine Sequenznummer, die genau die erste Bytenummer des Segments ist. Die Bestätigungsnummer im TCP-Header ist immer die Sequenznummer des Seg- ments, das der Empfänger als nächstes erwartet.
Als Beispiel schauen wir ein vereinfachtes TCP-Senderprogramm an,
1. das keine Flusskontrolle (siehe Abschnitt 3.4.5.6) realisiert,
2. das Daten vom Anwendungsprozess erhält, die kleiner als die maximale Segmentgröße sind, und
3. das nur unidirektionalen Datentransfer vom Sender zum Empfänger durchführt.
Das Programm muss die drei folgenden Ereignisse bewältigen: 1. TCP erhält Daten vom Anwendungsprozess.
2. Ein Timer ist abgelaufen.
3. Ein ACK-Segment ist angekommen.
Das Programm zeigt, wie der TCP-Senderprozess die drei Ereignisse be-
handelt:
1. Er empfängt Daten vom Anwendungsprozess, verpackt diese in Segmente und übergibt sie zur Übertragung an die Vermittlungsschicht. Der Timer wird gestartet, falls er momentan nicht aktiv ist. Dies kann der Fall sein, wenn beispielsweise alle bisher gesendeten Segmente schon bestätigt wurden.
2. Wenn der Timer abläuft, dann wiederholt der Senderprozess die Über- tragung des unbestätigten Segments mit der kleinsten Sequenznummer.
3. Wenn ein Segment mit Bestätigungsnummer N im ACK-Feld ankommt, dann prüft der Sender zuerst, ob es sich um eine Bestätigung für ein bis jetzt noch nicht bestätigtes Segment handelt. Dies ist genau dann der Fall, wenn N größer ist als die Sequenznummer des letzten vom Empfän- ger bestätigt Byte. Der Sender weiß dann, dass der Empfänger alle Daten korrekt empfangen hat, die vor der Sequenznummer N liegen. Deshalb kann der Sender seine Zustandsvariable sendbase, die die Sequenznum- mer des letzten vom Empfänger noch nicht bestätigten Bytes enthält, auf den neuen Wert N setzen.
Falls aber vorher schon einmal eine Bestätigung mit demselben Wert N im ACK-Feld empfangen wurde (d. h. N ≤ sendbase), dann handelt es sich um ein sogenanntes Duplicate ACK. In diesem Fall ignoriert der Sender die Bestätigung, falls N < sendbase ist. Falls N = sendbase, weiß der Sender, dass der Empfänger das Segment mit der Sequenznum- mer N nicht korrekt empfangen hat, siehe auch Abbildung 3.25. Der Sender erhöht deshalb einen Zähler für die Anzahl der Duplicate ACK für das betroffene Segment. Tatsächlich entspricht ein Duplicate ACK einer negativen Bestätigung.
Wenn der Sender drei Duplicate ACKs mit dem Wert N = sendbase erhalten hat, dann nimmt er an, dass das Segment mit Sequenznummer N verloren gegangen ist und überträgt es erneut – auch wenn der Timer noch nicht abgelaufen sein sollte. Der Zähler für die Anzahl der Duplicate ACKs für das wieder übertragene Segment wird auf Null zurückgesetzt. Man spricht deshalb auch von einem Fast Retransmit.
Das bis jetzt diskutierte TCP-Protokoll weist noch ein Problem auf. Jeder TCP-Prozess hat für jede Verbindung einen Empfangspuffer, in den die kor- rekt angekommenen Anwendungsdaten in der richtigen Reihenfolge eingefügt werden. Aus diesem Puffer liest der Anwendungsprozess Daten und macht da- durch wieder Platz für neu ankommende Daten. Falls aber der Senderprozess schneller Daten sendet, als sie vom Empfängerprozess gelesen werden, wird ein endlich großer Puffer nach einiger Zeit überlaufen. Dieses Problem kann häufig auftreten, da der Empfängerprozess durch andere Aktivitäten am Lesen der Daten gehindert werden kann, oder sogar gerade gar nicht aktiv sein kann (weil z. B. das Betriebssystem den Prozess gerade nicht ausführt).
Um dieses Problem zu lösen, bietet TCP einen Flusskontrolldienst (Flow Control Service). Mit diesem Dienst kann der Empfänger die Senderate des Senders so verringern, dass der Empfangspuffer nicht überläuft. Dazu hat jeder TCP-Prozess eine Variable, die man Empfangsfenster (receive window) nennt, siehe Abbildung 3.30. Dieses Empfangsfenster zeigt an, wie viel freier Puffer- platz noch beim Empfänger vorhanden ist. Wann immer der Sender Daten sendet, zieht er den zur Speicherung notwendigen Platz vom Empfangsfenster ab. Falls kein Patz mehr da ist, sendet der Sender keine weiteren Daten. Damit dies funktioniert, teilt der Empfänger dem Sender in jedem Segment, das er an den Sender schickt, in dem WINDOW-Feld des TCP-Headers mit, wie viel freien Platz er im Puffer hat. Nun kann der Sender jeweils maximal so viele Daten senden, wie noch Pufferplatz übrig ist. Wenn der Empfängerpuffer voll ist, wartet der Sender, bis er vom Empfänger ein Segment erhält, in dem wie- der neuer freier Platz gemeldet wird. Damit dies auch dann funktioniert, wenn der Empfänger gerade keine Anwendungsdaten an den Sender zu schicken hat, muss der Empfänger in diesem Fall ein leeres Segment ohne Dateninhalt an den Sender schicken, in dem er den freien Empfangspufferplatz mitteilt. Sonst wä- re der Sender blockiert, und könnte trotz freien Empfangspuffers keine Daten mehr senden.
Es gibt noch einen weiteren Fall, in dem die Verringerung der Senderate des Senders sinnvoll ist. Falls das Netzwerk überlastet ist, macht es Sinn, die Senderate zu verringern. Dies nennt man auch Überlastkontrolle (Congestion Control). Obwohl die Lösung des Überlastproblems auch die Reduzierung der Senderate erfordert, handelt es sich um ein unterschiedliches Problem, da es durch andere Ursachen entsteht.
Die Transportsschicht des Internet bietet mit UDP und TCP zwei verschie- dene Transportdienste an. TCP bietet einen zuverlässigen Datenübertragungs- service, während UDP nur einen unzuverlässigen Datenübertragungsservice bietet. Wann sollte ein Anwendungsentwickler nun welches Protokoll benut- zen?
UDP weist neben der eingeschränkten Zuverlässigkeit auch eine Reihe von Vorteilen auf:
• UDP ist ein verbindungsloses Protokoll und kommt daher ohne Verbin- dungsaufbau und Verbindungsabbau aus;
• UDP speichert keinen Verbindungszustand und kommt daher mit einer einfacheren Implementierung aus. Ein Serverprozess, der mit UDP arbei- tet, kann daher deutlich mehr Clients bedienen;
• UDP kommt mit einem Header von nur 8 Byte aus. Dies verringert den administrativen Aufwand gegenüber TCP, das einen 20 Byte langen Hea- der aufweist. Pro Segment kann UDP 12 Byte mehr übertragen;
• UDP erlaubt Anwendungen so viele Daten pro Zeiteinheit zu versenden, wie sie Daten generieren (abhängig von Algorithmus, CPU etc.) und über die Netzwerkkarte in das Internet einspeisen können. Dies bedeutet jedoch nicht, dass alle diese Daten auch beim Empfänger ankommen. Ins- besondere kann es aufgrund von Überlast zu Nachrichtenverlusten kom- men.
Aufgrund obiger Vorteile wird UDP z. B. von den folgenden Internetanwen- dungen benutzt:
• Remote file server (NFS: Network File System)
• Streaming Multimedia Anwendungen, die einen schnellen Datentransfer brauchen und mit Nachrichtenverlusten leben können (z. B. Video-Über- tragungen)
• Internet Telephony Anwendungen, die bei Nachrichtenverlusten eine et- was schlechtere (aber oft noch verständliche) Sprachqualität liefern kön- nen
• Network Management Anwendungen (SNMP: Simple Network Manage- ment Protocol, [13]) kontrollieren Netzwerke, die bei Überlastung des Netzes noch am ehesten UDP-Kommunikation durchführen können
• Das Routing Protocol (RIP: Routing Internet Protocol, [20], [24]) ver- sendet periodisch neue Routing-Tabellen (siehe Kurseinheit 4), die in der Vermittlungsschicht des Internet zur Steuerung des Paketflusses einge- setzt werden. Bei Verlust einer neuen Routing-Tabelle kommt das nächste Update schnell.
• Das Domain Name System (DNS, [25, 26]) übersetzt symbolische Namen in IP-Adressen, siehe Abschnitt 3.3.4. Bei Verlust einer Anfrage wird die kurze Anfrage erneut gestellt oder an einen anderen Server gerichtet.
TCP realisiert einen zuverlässigen bidirektionalen Datenübertragungs- dienst mit Flusskontrolle. Deshalb entlastet TCP den Anwendungsprogram- mierer von der expliziten Behandlung von Bit-Fehlern, Paketverlusten, Paket- vertauschungen und Pufferüberläufen im Anwendungsprogramm. Mit diesen angenehmen Leistungen sind aber auch ein paar Nachteile verbunden:
• TCP ist ein verbindungsorientiertes Protokoll. Damit einher geht eine initiale Verzögerung bei der Datenübertragung (verursacht durch das 3- Wege-Handschlag-Verfahren beim Verbindungsaufbau). Dies ist eine der Hauptursachen für die Wartezeiten beim WWW, denn bei HTTP Version 1.0 wird für jede Anforderungsnachricht eine neue Verbindung aufgebaut.
• TCP speichert den Verbindungszustand in der TCP-Implementierung auf Sender- und Empfängerseite. Diese Informationen (Puffer, Zustands- variable) werden zur Verwaltung der Verbindung und zur Erbringung der Diensteigenschaften benötigt. Daher kann ein Server, der mit TCP arbeitet, weniger Clients bedienen als ein gleich ausgestatteter Server, der mit UDP arbeitet.
• Der TCP Header ist 20 Byte lang gegenüber 8 Byte bei UDP. TCP verbraucht also mehr Bandbreite für Verwaltungsinformation als UDP.
• TCP bietet eine Flusskontrolle, die den Senderprozess am Verschicken zu vieler Nachrichten hindert. Dies ist dann ein Nachteil, wenn eine Echt- zeitanwendung zwar Paketverluste tolerieren kann, aber immer eine mini- male Senderate haben muss (z. B. bei der Übertragung von Live Video).
TCP wird z. B. von den folgenden Internetanwendungen benutzt: 
• Electronic Mail (SMTP)
• Remote Terminal Access (Telnet)
• WWW (HTTP)
• File Transfer (FTP)